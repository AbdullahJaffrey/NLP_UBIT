{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts4lqpuumTlm",
        "outputId": "3aba8d31-be41-46fa-957f-8a490cc50d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load spaCy model for English\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load NLTK Porter Stemmer and stopwords\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load Lemmatizer\n",
        "lemmar = WordNetLemmatizer()\n",
        "\n",
        "# Sample text\n",
        "text = \"My name is Abdullah Jafri and I'm currently studying computer science from Karachi University.\"\n",
        "\n",
        "# Tokenization\n",
        "doc = nlp(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZc53mQAmvpH",
        "outputId": "3a308f95-324b-4230-9375-933d5e5eac78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['My', 'name', 'is', 'Abdullah', 'Jafri', 'and', 'I', \"'m\", 'currently', 'studying', 'computer', 'science', 'from', 'Karachi', 'University', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Stemmer (using NLTK)\n",
        "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "print(\"Stemmed Tokens:\", stemmed_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op09BuHPmtwX",
        "outputId": "347dca5c-946c-412e-c1fa-a44b82b2f92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Tokens: ['my', 'name', 'is', 'abdullah', 'jafri', 'and', 'i', \"'m\", 'current', 'studi', 'comput', 'scienc', 'from', 'karachi', 'univers', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize(using NLTK)\n",
        "lem_tokens = [lemmar.lemmatize(token) for token in tokens]\n",
        "print(\"Lemmed Tokens:\", lem_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fESzMCobMn2m",
        "outputId": "9f32e229-c6a6-470b-b9d9-7f0b6b784a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmed Tokens: ['My', 'name', 'is', 'Abdullah', 'Jafri', 'and', 'I', \"'m\", 'currently', 'studying', 'computer', 'science', 'from', 'Karachi', 'University', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text Normalization (lowercasing)\n",
        "normalized_text = text.lower()\n",
        "print(\"Normalized Text:\", normalized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFdq_81mmsHP",
        "outputId": "d9e1a67e-eb96-4fbd-fb95-1991e05b0687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Text: my name is abdullah jafri and i'm currently studying computer science from karachi university.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Stopword Removal\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "print(\"Tokens after Stopword Removal:\", filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGCVGX5dmo8Q",
        "outputId": "aea966c5-e6fc-44f0-e212-18123a20cf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after Stopword Removal: ['name', 'Abdullah', 'Jafri', \"'m\", 'currently', 'studying', 'computer', 'science', 'Karachi', 'University', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sentence Segmentation\n",
        "sentences = [sent.text for sent in doc.sents]\n",
        "print(\"Sentences:\", sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ3eR-XymmQI",
        "outputId": "06d3a0d6-5a0b-43fa-bd83-da8f22f3258b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: [\"My name is Abdullah Jafri and I'm currently studying computer science from Karachi University.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Part-of-Speech Tagging (POS)\n",
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(\"POS Tags:\", pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvCQMSN5mlCB",
        "outputId": "d04a40de-ab60-4f43-967a-59e9216ff0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('My', 'PRON'), ('name', 'NOUN'), ('is', 'AUX'), ('Abdullah', 'PROPN'), ('Jafri', 'PROPN'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('currently', 'ADV'), ('studying', 'VERB'), ('computer', 'NOUN'), ('science', 'NOUN'), ('from', 'ADP'), ('Karachi', 'PROPN'), ('University', 'PROPN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Named Entity Recognition (NER)\n",
        "ner_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "print(\"Named Entities:\", ner_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFBUYJx6mjKQ",
        "outputId": "a6af4600-e6b4-4d4c-a9a6-9f6cc4c0dd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: [('Abdullah Jafri', 'PERSON'), ('Karachi University', 'ORG')]\n"
          ]
        }
      ]
    }
  ]
}